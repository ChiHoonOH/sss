{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt\n",
    "from xgboost import  XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "import xgboost\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "if platform.system() == 'Darwin':    # 맥\n",
    "    rc( 'font', family='AppleGothic' )\n",
    "elif platform.system() == 'Windows': # 윈도우\n",
    "    fontPath = 'c:/Windows/Fonts/malgun.ttf'\n",
    "    fontName = font_manager.FontProperties( fname=fontPath ).get_name()\n",
    "    rc( 'font', family=fontName )\n",
    "else:\n",
    "    print('알수없는 시스템. 미적용')\n",
    "    \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.read_excel('./true.xlsx')\n",
    "\n",
    "col = ['종가 (5일 평균)(원)_1일변화율',\n",
    "       '변동성 (5일)_1일변화율', '순매수수량(외국인계)(20일합산)(주)_1일변화율', 'PER(IFRS-연결)_1일변화율',\n",
    "       '순매수수량(개인)(20일합산)(주)_1일변화율', '종가 (60일 평균)(원)_1일변화율',\n",
    "       '거래량 (20일 평균)(주)_1일변화율', '순매수수량(외국인계)(60일합산)(주)_1일변화율',\n",
    "       '순매수수량(기관/외국인계)(60일합산)(주)_1일변화율', '순매수수량(외국인계)(주)_1일변화율',\n",
    "       '순매수수량(기관계)(주)_1일변화율', '순매수수량(기관계)(60일합산)(주)_1일변화율',\n",
    "       '순매수수량(개인)(주)_1일변화율', '외국인보유비중(티커)(%)_1일변화율', 'PSR(IFRS-연결)_1일변화율',\n",
    "       '종가 (120일 평균)(원)_1일변화율', '종가 (20일 평균)(원)_1일변화율',\n",
    "       '순매수수량(개인)(60일합산)(주)_1일변화율', '거래량 (60일 평균)(주)_1일변화율',\n",
    "       'PCR(IFRS-연결)_1일변화율', '순매수수량(기관/외국인계)(20일합산)(주)_1일변화율',\n",
    "       '순매수수량(기관계)(20일합산)(주)_1일변화율', '수익률 (1주)(%)_1일변화율', 'PBR(IFRS-연결)_1일변화율',\n",
    "       '거래량 (5일 평균)(주)_1일변화율', '순매수수량(기관/외국인계)(주)_1일변화율',\n",
    "       '종가 (5일 평균)(원)_2일변화율', '변동성 (5일)_2일변화율', '순매수수량(외국인계)(20일합산)(주)_2일변화율',\n",
    "       'PER(IFRS-연결)_2일변화율', '순매수수량(개인)(20일합산)(주)_2일변화율',\n",
    "       '종가 (60일 평균)(원)_2일변화율', '거래량 (20일 평균)(주)_2일변화율',\n",
    "       '순매수수량(외국인계)(60일합산)(주)_2일변화율', '순매수수량(기관/외국인계)(60일합산)(주)_2일변화율',\n",
    "       '순매수수량(외국인계)(주)_2일변화율', '순매수수량(기관계)(주)_2일변화율',\n",
    "       '순매수수량(기관계)(60일합산)(주)_2일변화율', '순매수수량(개인)(주)_2일변화율',\n",
    "       '외국인보유비중(티커)(%)_2일변화율', 'PSR(IFRS-연결)_2일변화율', '종가 (120일 평균)(원)_2일변화율',\n",
    "       '종가 (20일 평균)(원)_2일변화율', '순매수수량(개인)(60일합산)(주)_2일변화율',\n",
    "       '거래량 (60일 평균)(주)_2일변화율', 'PCR(IFRS-연결)_2일변화율',\n",
    "       '순매수수량(기관/외국인계)(20일합산)(주)_2일변화율', '순매수수량(기관계)(20일합산)(주)_2일변화율',\n",
    "       '수익률 (1주)(%)_2일변화율', 'PBR(IFRS-연결)_2일변화율', '거래량 (5일 평균)(주)_2일변화율',\n",
    "       '순매수수량(기관/외국인계)(주)_2일변화율','수익률(%)(2)','Name']\n",
    "data =  final_dataset[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= ['변동성 (5일)_1일변화율',\n",
    " '순매수수량(외국인계)(20일합산)(주)_1일변화율',\n",
    " '순매수수량(기관계)(주)_1일변화율',\n",
    " '외국인보유비중(티커)(%)_1일변화율',\n",
    " '종가 (120일 평균)(원)_1일변화율',\n",
    " '거래량 (60일 평균)(주)_1일변화율',\n",
    " '순매수수량(기관/외국인계)(20일합산)(주)_1일변화율',\n",
    " '거래량 (5일 평균)(주)_1일변화율',\n",
    " '변동성 (5일)_2일변화율',\n",
    " '순매수수량(개인)(20일합산)(주)_2일변화율',\n",
    " '종가 (60일 평균)(원)_2일변화율',\n",
    " '거래량 (20일 평균)(주)_2일변화율',\n",
    " '순매수수량(외국인계)(60일합산)(주)_2일변화율',\n",
    " '외국인보유비중(티커)(%)_2일변화율',\n",
    " '순매수수량(개인)(60일합산)(주)_2일변화율',\n",
    " '순매수수량(기관계)(20일합산)(주)_2일변화율',\n",
    " '수익률 (1주)(%)_2일변화율',\n",
    " '순매수수량(기관/외국인계)(주)_2일변화율']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sp(data):\n",
    "    com_name_set = list(set(data.Name))\n",
    "    \n",
    "    train_set = pd.DataFrame()\n",
    "    test_set = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(com_name_set)):\n",
    "        sub_set = data[ data.Name == com_name_set[i]]\n",
    "        train_set = train_set.append(sub_set[:-60])\n",
    "        test_set = test_set.append(sub_set[-60:])\n",
    "    return train_set , test_set\n",
    "\n",
    "train, test = data_sp(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[cols]\n",
    "X_test = test[cols]\n",
    "\n",
    "Y_train = train['수익률(%)(2)']\n",
    "Y_test = test['수익률(%)(2)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernel = ['linear', 'rbf', 'sigmoid']#'precomputed','poly'\n",
    "nfolds=5\n",
    "criterion = [\"gini\", 'entropy']\n",
    "#grid_search = GridSearchCV(SVC(), param_grid_svc, cv=nfolds)\n",
    "n_estimators = [500,1000,1500]\n",
    "learning_rate = [0.01]\n",
    "max_depth = [4,5,6]\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "scoring = 'accuracy'\n",
    "n_jobs= -1\n",
    "penalty= ['l2']\n",
    "max_features = [2]\n",
    "linearscv_param_grid = {'C':Cs, 'penalty':penalty, 'random_state':random_state }\n",
    "random_state = [4000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 랜덤포레스트 튜닝\n",
    "\n",
    "SVC_acc = []\n",
    "SVC_pre = []\n",
    "SVC_param = []\n",
    "'C': Cs, 'gamma' : gammas,'kernel':kernel, 'random_state':random_state\n",
    "for i in Cs:\n",
    "    for b in kernel:\n",
    "        for c in gammas:\n",
    "            model = SVC(C = i,\n",
    "                       kernel = b,\n",
    "                       gamma = c,\n",
    "                       random_state = random_state)\n",
    "\n",
    "            model.fit(X_train ,Y_train)\n",
    "            a = model.predict(X_test)\n",
    "            t = metrics.confusion_matrix(Y_test,a)\n",
    "\n",
    "            SCV_acc.append(metrics.accuracy_score(a,Y_test))\n",
    "            SCV_pre.append(t[1,1]/t[:,1].sum())\n",
    "            SCV_param.append(model)\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 랜덤포레스트 튜닝\n",
    "\n",
    "RF_acc = []\n",
    "RF_pre = []\n",
    "RF_param = []\n",
    "for i in max_depth:\n",
    "    for b in n_estimators:\n",
    "        for c in criterion:\n",
    "            model = RandomForestClassifier(max_depth = i,\n",
    "                                           estimators = b,\n",
    "                                           criterion = c)\n",
    "\n",
    "            model.fit(X_train ,Y_train)\n",
    "            a = model.predict(X_test)\n",
    "            t = metrics.confusion_matrix(Y_test,a)\n",
    "\n",
    "            RF_acc.append(metrics.accuracy_score(a,Y_test))\n",
    "            RF_pre.append(t[1,1]/t[:,1].sum())\n",
    "            RF_param.append(model)\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 로지스틱 튜닝\n",
    "\n",
    "LG_acc = []\n",
    "LG_pre = []\n",
    "LG_param = []\n",
    "\n",
    "for i in Cs:\n",
    "    model = RandomForestClassifier(C = i)\n",
    "\n",
    "    model.fit(X_train ,Y_train)\n",
    "    a = model.predict(X_test)\n",
    "    t = metrics.confusion_matrix(Y_test,a)\n",
    "\n",
    "    LG_acc.append(metrics.accuracy_score(a,Y_test))\n",
    "    LG_pre.append(t[1,1]/t[:,1].sum())\n",
    "    LG_param.append(model)\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
